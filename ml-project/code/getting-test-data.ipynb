{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJSON(filepath):\n",
    "    with open(filepath) as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu API key de Messari\n",
    "api_key = os.getenv('MESSARI_ANDRE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON\n",
    "def obt_ids(file_path):   \n",
    "   \n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extraer los IDs\n",
    "    ids = [item['id'] for item in data]\n",
    "\n",
    "    # Mostrar los IDs extraídos\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de ids_ia:  31\n",
      "Tamaño de ids_gaming:  59\n",
      "Tamaño de ids_gaming:  18\n",
      "Tamaño de ids_gaming:  16\n"
     ]
    }
   ],
   "source": [
    "ids_ia = obt_ids('../data/processed/ai_complete_time_series.json')\n",
    "print(\"Tamaño de ids_ia: \", len(ids_ia))\n",
    "\n",
    "ids_gaming = obt_ids('../data/processed/gaming_complete_time_series.json')\n",
    "print(\"Tamaño de ids_gaming: \", len(ids_gaming))\n",
    "\n",
    "ids_meme = obt_ids('../data/processed/meme_complete_time_series.json')\n",
    "print(\"Tamaño de ids_gaming: \", len(ids_meme))\n",
    "\n",
    "ids_rwa = obt_ids('../data/processed/rwa_complete_time_series.json')\n",
    "print(\"Tamaño de ids_gaming: \", len(ids_rwa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_api(endpoint: str, API_KEY: str):\n",
    "    base_url = 'https://api.messari.io/'\n",
    "    url = f'{base_url}{endpoint}'\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'x-messari-api-key': API_KEY,\n",
    "    }\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "# API key from environment variable\n",
    "API_KEY = os.getenv('MESSARI_ANDRE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the dataframes: (250, 17) (400, 17) (500, 17) (100, 17)\n",
      "Number of tokens:  1250\n"
     ]
    }
   ],
   "source": [
    "ai_df = pd.read_csv('../../logical-model/data/csv/coins_AI.csv')\n",
    "gaming_df = pd.read_csv('../../logical-model/data/csv/coins_gaming.csv')\n",
    "meme_df = pd.read_csv('../../logical-model/data/csv/coins_meme.csv')\n",
    "rwa_df = pd.read_csv('../../logical-model/data/csv/coins_RWA.csv')\n",
    "\n",
    "print(\"Shapes of the dataframes:\", ai_df.shape, gaming_df.shape, meme_df.shape, rwa_df.shape)\n",
    "print(\"Number of tokens: \", ai_df.shape[0] + gaming_df.shape[0] + meme_df.shape[0] + rwa_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_market_cap(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_without_null = df.dropna(subset=['market_cap'])\n",
    "    return df_without_null[df_without_null['market_cap'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the dataframes: (167, 17) (261, 17) (220, 17) (75, 17)\n",
      "Number of tokens:  723\n"
     ]
    }
   ],
   "source": [
    "ai_df = remove_non_market_cap(ai_df)\n",
    "gaming_df = remove_non_market_cap(gaming_df)\n",
    "meme_df = remove_non_market_cap(meme_df)\n",
    "rwa_df = remove_non_market_cap(rwa_df)\n",
    "\n",
    "print(\"Shapes of the dataframes:\", ai_df.shape, gaming_df.shape, meme_df.shape, rwa_df.shape)\n",
    "print(\"Number of tokens: \", ai_df.shape[0] + gaming_df.shape[0] + meme_df.shape[0] + rwa_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14731"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = loadJSON('../data/raw/all-tokens.json')\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_category(category_df: pd.DataFrame, tokens: list) -> pd.DataFrame:\n",
    "    return [\n",
    "        record for record in tokens\n",
    "        if (record['name'] in category_df['name'].values) and\n",
    "        # (record['slug'] in category_df['slug'].values) and\n",
    "        (record['symbol'] in category_df['symbol'].astype(str).values)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 80 117 34 38\n",
      "Number of tokens: 269\n"
     ]
    }
   ],
   "source": [
    "meme = filter_by_category(category_df=meme_df, tokens=tokens)\n",
    "gaming = filter_by_category(category_df=gaming_df, tokens=tokens)\n",
    "ai = filter_by_category(category_df=ai_df, tokens=tokens)\n",
    "rwa = filter_by_category(category_df=rwa_df, tokens=tokens)\n",
    "\n",
    "print(\"Number of tokens:\", len(ai), len(gaming), len(meme), len(rwa))\n",
    "print(\"Number of tokens:\", len(meme) + len(gaming) + len(ai) + len(rwa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i have the ids, just keep the ones that are in the list\n",
    "def filter_by_ids(ids: list, tokens: list) -> list:\n",
    "    return [record for record in tokens if record['id'] in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 31 59 18 16\n",
      "Number of tokens: 124\n"
     ]
    }
   ],
   "source": [
    "meme = filter_by_ids(ids=ids_meme, tokens=meme)\n",
    "gaming = filter_by_ids(ids=ids_gaming, tokens=gaming)\n",
    "ai = filter_by_ids(ids=ids_ia, tokens=ai)\n",
    "rwa = filter_by_ids(ids=ids_rwa, tokens=rwa)\n",
    "\n",
    "print(\"Number of tokens:\", len(ai), len(gaming), len(meme), len(rwa))\n",
    "print(\"Number of tokens:\", len(meme) + len(gaming) + len(ai) + len(rwa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_interval_timestamps(date: str, days:int) -> tuple[int, int]:\n",
    "    startdate: datetime = datetime.strptime(date, '%d/%m/%Y')\n",
    "    enddate: datetime = startdate + timedelta(days=days)\n",
    "    return int(datetime.timestamp(startdate)), int(datetime.timestamp(enddate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(date_since:str, interval:str, tokens: list, category: str)->None:\n",
    "    year = date_since\n",
    "\n",
    "    while(1):\n",
    "        print(f\"Getting data since {year}\")\n",
    "        annual_data = []\n",
    "\n",
    "        days = 360\n",
    "\n",
    "        if datetime.now() - timedelta(days=360) < datetime.strptime(year, \"%d/%m/%Y\"):\n",
    "            days = int((datetime.now() - datetime.strptime(year, \"%d/%m/%Y\")).days)\n",
    "        \n",
    "        start_timestamp, end_timestamp = getting_interval_timestamps(year, days)\n",
    "        print(f\"{start_timestamp} - {end_timestamp} ({days} days)\")\n",
    "        \n",
    "        for token in tokens:\n",
    "            new_token = token.copy()\n",
    "            del new_token['allTimeHighData']\n",
    "            del new_token['cycleLowData']\n",
    "            new_token['category'] = category\n",
    "            endpoint = f\"marketdata/v1/assets/{token['id']}/price/time-series?interval={interval}&startTime={start_timestamp}&endTime={end_timestamp}\"\n",
    "            response = get_from_api(endpoint, API_KEY)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                new_token['market_data'] = result['data']\n",
    "            else:\n",
    "                new_token['market_data'] = \"No content\"\n",
    "            annual_data.append(new_token)\n",
    "        \n",
    "        with open(f'../data/processed/test/{category}-{date_since.replace(\"/\", \"-\")}.json', 'w') as json_file:\n",
    "            json.dump(annual_data, json_file, indent=4)\n",
    "        \n",
    "        # updating year\n",
    "        next_year = datetime.strptime(year, \"%d/%m/%Y\") + timedelta(days=days)\n",
    "        year = next_year.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "        if days < 360:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data since 28/10/2024\n",
      "1730091600 - 1730696400 (7 days)\n"
     ]
    }
   ],
   "source": [
    "get_test_data('28/10/2024', '1d', meme, 'meme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data since 28/10/2024\n",
      "1730091600 - 1730696400 (7 days)\n"
     ]
    }
   ],
   "source": [
    "get_test_data('28/10/2024', '1d', gaming, 'gaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data since 28/10/2024\n",
      "1730091600 - 1730696400 (7 days)\n"
     ]
    }
   ],
   "source": [
    "get_test_data('28/10/2024', '1d', ai, 'ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data since 28/10/2024\n",
      "1730091600 - 1730696400 (7 days)\n"
     ]
    }
   ],
   "source": [
    "get_test_data('28/10/2024', '1d', rwa, 'rwa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 31 59 18 16\n"
     ]
    }
   ],
   "source": [
    "meme_complete = loadJSON('../data/processed/test/meme-28-10-2024.json')\n",
    "gaming_complete = loadJSON('../data/processed/test/gaming-28-10-2024.json')\n",
    "ai_complete = loadJSON('../data/processed/test/ai-28-10-2024.json')\n",
    "rwa_complete = loadJSON('../data/processed/test/rwa-28-10-2024.json')\n",
    "\n",
    "print(\"Number of tokens:\", len(ai_complete), len(gaming_complete), len(meme_complete), len(rwa_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_json_to_dataframe(json_file: list) -> pd.DataFrame:\n",
    "    # json_file has the property 'market_data' that is a list of dictionaries i want every single one of them to be a row with and put the name, symbol and id aswell\n",
    "    data = []\n",
    "    for token in json_file:\n",
    "        for record in token['market_data']:\n",
    "            new_record = record.copy()\n",
    "            new_record['name'] = token['name']\n",
    "            new_record['symbol'] = token['symbol']\n",
    "            new_record['id'] = token['id']\n",
    "            new_record['category'] = token['category']\n",
    "            data.append(new_record)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_df = test_json_to_dataframe(meme_complete)\n",
    "gaming_df = test_json_to_dataframe(gaming_complete)\n",
    "ai_df = test_json_to_dataframe(ai_complete)\n",
    "rwa_df = test_json_to_dataframe(rwa_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_df.to_csv('../data/processed/test/meme.csv', index=False)\n",
    "gaming_df.to_csv('../data/processed/test/gaming.csv', index=False)\n",
    "ai_df.to_csv('../data/processed/test/ai.csv', index=False)\n",
    "rwa_df.to_csv('../data/processed/test/rwa.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
